#!/usr/bin/env python
"""
1. Fetch top stories
2. Determine word count
3. Filter stories by min score and min word count
4. Send filtered stories to Instapaper

Rules

* Never add the same story to Instapaper twice
"""
from __future__ import print_function
import argparse
import json
import os
import sys

import goose
import requests


DATA_FILE = os.path.expanduser('~/.HNstapaper-data.json')
HN_API_URL = 'https://hacker-news.firebaseio.com/v0/'


def _fetch_hn_json(url):
    resp = requests.get(HN_API_URL + url + '.json')
    if resp.status_code != 200:
        raise Exception("HN returned non-200 result")
    return json.loads(resp.content)


def log(verbosity, msg, level=0):
    if verbosity > level:
        print(msg, file=sys.stderr)


def fetch_top_stories(story_cache, verbosity):
    """Fetch top stories sorted from newest to oldest."""
    # Clean cache by dropping old entries
    # story_cache JSON dict stores keys as unicode even though they are ints
    story_ids = set(map(unicode, _fetch_hn_json('topstories')))
    cached_ids = set(story_cache.keys())
    old_keys = cached_ids - story_ids
    for key in old_keys:
        log(verbosity, "Evicting '{}' from cache".format(key),
            level=1)
        del story_cache[key]

    # Fetch and cache new top stories
    stories = []
    for story_id in story_ids:
        if story_id not in story_cache:
            log(verbosity, "Fetching story '{}'".format(story_id))
            story = _fetch_hn_json('item/' + story_id)
            story_cache[story_id] = story

        story = story_cache[story_id]
        stories.append((story['time'], story))

    for story_time, story in sorted(stories, reverse=True):
        yield story


def fetch_word_count(url):
    article = goose.Goose().extract(url=url)
    word_count = len(article.cleaned_text.split(' '))
    return word_count


def fetch_acceptable_stories(story_cache, min_score, min_word_count,
                             verbosity):
    """Fetch stories that meet min_score and min_word_count"""
    for story in fetch_top_stories(story_cache, verbosity):
        if story['score'] < min_score:
            continue
        url = story.get('url')
        if not url:
            continue
        word_count = fetch_word_count(url)
        if word_count >= min_word_count:
            yield word_count, story


def add_to_instapaper(url, user, passwd):
    resp = requests.post('https://www.instapaper.com/api/add',
                         params=dict(url=url),
                         auth=(user, passwd))
    if resp.status_code != 201:
        raise Exception("Error adding '{}' to Instapaper: {}".format(url,
                        resp.status_code))


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('-c', '--clear', action='store_true',
                        help="Clear cached data")
    parser.add_argument('-d', '--dry-run', action='store_true')
    parser.add_argument('-l', '--limit', type=int, help="Limit number of articles sent")
    parser.add_argument('-p', '--password', help="Instapaper password")
    parser.add_argument('-s', '--score', type=int, help="Minimum score", default=200)
    parser.add_argument('-u', '--user', help="Instapaper username",
                        required=True)
    parser.add_argument('-v', dest='verbosity', action='count',
                        help="Set verbosity", default=0)
    parser.add_argument('-w', '--words', type=int, help="Minimum word count",
                        default=1000)
    args =  parser.parse_args()

    # Read data file
    data = {}
    if os.path.exists(DATA_FILE):
        if args.clear:
            os.unlink(DATA_FILE)
        else:
            with open(DATA_FILE) as f:
                data = json.load(f)

    story_cache = data.get('story_cache', {})
    sent_ids = set(data.get('sent_ids', []))
    num_sent = 0
    try:
        for word_count, story in fetch_acceptable_stories(story_cache,
                args.score, args.words, args.verbosity):
            if args.limit is not None and num_sent >= args.limit:
                log(args.verbosity,
                    "Limit {} reached, exiting...".format(args.limit))
                break
            story_id = story['id']
            ascii_title = story['title'].encode('ascii', 'ignore')
            if story_id in sent_ids:
                log(args.verbosity, "Already added '{}'".format(ascii_title))
            else:
                log(args.verbosity, "Adding score={} wc={} title='{}'".format(
                    story['score'], word_count, ascii_title))

                if not args.dry_run:
                    try:
                        add_to_instapaper(story['url'], args.user, args.password)
                    except Exception as e:
                        print(e, file=sys.stderr)
                        sys.exit(1)

                    sent_ids.add(story_id)
                num_sent += 1
    finally:
        data['story_cache'] = story_cache

        # JSON cannot serialize sets() so convert to list
        data['sent_ids'] = list(sent_ids)

        # Write out data file (even in case of exception)
        with open(DATA_FILE, 'w') as f:
            json.dump(data, f)


if __name__ == '__main__':
    main()
